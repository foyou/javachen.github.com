
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>hive中如何确定map数 - JavaChen Blog</title>
    <meta name="description" content="hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。当运行一个hql语句的时候，map数是如何计算出来的呢？有哪些方法可以调整map数呢？">
    <meta name="keywords" content="pentaho、kettle、hadoop、hdfs、hive、hbase、mapreduce、cassandra、openstack、OpenNebula、Eucalyptus、fedora、linux、vim、extjs、dhtmlx、spring、javascript"/>
    <meta name="author" content="JavaChen">
    <meta name="copyright" content="© http://blog.javachen.com" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
    <![endif]-->

    <link href="//cdn.staticfile.org/twitter-bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet" media="all"/>
    <link href="//cdn.staticfile.org/font-awesome/3.2.1/css/font-awesome.min.css" rel="stylesheet"media="all">
    <link href="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet" media="all" />
    <link href="/assets/themes/bootstrap/css/style-min.css" rel="stylesheet" type="text/css" media="all" />
    <link href="/assets/themes/bootstrap/css/pygments-min.css" rel="stylesheet" type="text/css" media="all" />
  
    <!--[if lt IE 9]>
      <script src="/assets/themes/bootstrap/resources/respond/Respond.min.js"></script>
    <![endif]-->

    <link rel="shortcut icon" href="/favicon.ico" />
    <link rel="canonical" href="http://blog.javachen.com/hadoop/2013/09/04/how-to-decide-map-number" />
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">

  </head>

  <body>
    <nav class="navbar navbar-default" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/" title="JavaChen Blog">JavaChen Blog</a>
        </div>

        <div class="collapse navbar-collapse navbar-ex1-collapse">
          <ul class="nav navbar-nav">
            
            
            


  
    
      
      	
      	<li><a href="/tags.html">Tags</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
  
    
      
      	
      	<li><a href="/categories.html">Categories</a></li>
      	
      
    
  
    
      
      	
      	<li><a href="/archive.html">Archive</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/about.html">About</a></li>
      	
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  



          </ul>

 		 <ul class="nav navbar-nav navbar-right">
          <li><a href="http://blog.javachen.com/rss.xml" target="_blank" title="RSS"><span class="icon-rss icon-large"></span></a></li>
          
            <li><a href="https://github.com/javachen" target="_blank" title="Github"><span class="icon-github icon-large"></span></a></li>
          
          
          
          
          
            <li><a href="http://weibo.com/chenzhijun" target="_blank" title="Weibo"><span class="icon-weibo icon-large"></span></a></li>
          
        </ul>
        </div>
      </div>
    </nav>
    <div class="container">
      
<div class="page-header">
  <h1>hive中如何确定map数 </h1>
</div>

<div class="row post-full">
  <div class="col-md-12">
    <div class="date">
      <span>2013/09/04</span>
    </div>
    <div class="content">
      <p>hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。当运行一个hql语句的时候，map数是如何计算出来的呢？有哪些方法可以调整map数呢？</p>

<!-- more -->

<h1 id="toc_0">hive默认的input format</h1>

<p>在<code class="prettyprint">cdh-4.3.0</code>的hive中查看<code class="prettyprint">hive.input.format</code>值（为什么是<code class="prettyprint">hive.input.format</code>？）：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hive&gt; set hive.input.format;
hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
</code></pre></div>
<p>可以看到默认值为CombineHiveInputFormat，如果你使用的是<code class="prettyprint">IDH</code>的hive，则默认值为：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hive&gt; set hive.input.format;
hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
</code></pre></div>
<p>CombineHiveInputFormat类继承自HiveInputFormat，而HiveInputFormat实现了org.apache.hadoop.mapred.InputFormat接口，关于InputFormat的分析，可以参考<a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a>.</p>

<h1 id="toc_1">InputFormat接口功能</h1>

<p>简单来说，InputFormat主要用于描述输入数据的格式，提供了以下两个功能： </p>

<p>1)、数据切分，按照某个策略将输入数据且分成若干个split，以便确定Map Task的个数即Mapper的个数，在MapReduce框架中，一个split就意味着需要一个Map Task; </p>

<p>2)、为Mapper提供输入数据，即给定一个split(使用其中的RecordReader对象)将之解析为一个个的key/value键值对。 </p>

<p>该类接口定义如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">public interface InputFormat&lt;K,V&gt;{
    public InputSplit[] getSplits(JobConf job,int numSplits) throws IOException; 
    public RecordReader&lt;K,V&gt; getRecordReader(InputSplit split,JobConf job,Reporter reporter) throws IOException; 
}
</code></pre></div>
<p>其中，getSplit()方法主要用于切分数据，每一份数据由，split只是在逻辑上对数据分片，并不会在磁盘上将数据切分成split物理分片，实际上数据在HDFS上还是以block为基本单位来存储数据的。InputSplit只记录了Mapper要处理的数据的元数据信息，如起始位置、长度和所在的节点。</p>

<p>MapReduce自带了一些InputFormat的实现类： </p>

<p><img src="http://dl2.iteye.com/upload/attachment/0085/0423/fa2e8c9f-f26a-3184-98e7-277c1b56fda1.jpg" alt="InputFormat实现类"></p>

<p>hive中有一些InputFormat的实现类，如：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">AvroContainerInputFormat
RCFileBlockMergeInputFormat
RCFileInputFormat
FlatFileInputFormat
OneNullRowInputFormat
ReworkMapredInputFormat
SymbolicInputFormat
SymlinkTextInputFormat
HiveInputFormat
</code></pre></div>
<p>HiveInputFormat的子类有：</p>

<p><img src="http://jc-resource.qiniudn.com/images/2013/implement-of-hiveinputformat.png" alt="HiveInputFormat的子类"></p>

<h1 id="toc_2">HiveInputFormat</h1>

<p>以HiveInputFormat为例，看看其getSplit()方法逻辑：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">for (Path dir : dirs) {
  PartitionDesc part = getPartitionDescFromPath(pathToPartitionInfo, dir);
  // create a new InputFormat instance if this is the first time to see this
  // class
  Class inputFormatClass = part.getInputFileFormatClass();
  InputFormat inputFormat = getInputFormatFromCache(inputFormatClass, job);
  Utilities.copyTableJobPropertiesToConf(part.getTableDesc(), newjob);

  // Make filter pushdown information available to getSplits.
  ArrayList&lt;String&gt; aliases =
      mrwork.getPathToAliases().get(dir.toUri().toString());
  if ((aliases != null) &amp;&amp; (aliases.size() == 1)) {
    Operator op = mrwork.getAliasToWork().get(aliases.get(0));
    if ((op != null) &amp;&amp; (op instanceof TableScanOperator)) {
      TableScanOperator tableScan = (TableScanOperator) op;
      pushFilters(newjob, tableScan);
    }
  }

  FileInputFormat.setInputPaths(newjob, dir);
  newjob.setInputFormat(inputFormat.getClass());
  InputSplit[] iss = inputFormat.getSplits(newjob, numSplits / dirs.length);
  for (InputSplit is : iss) {
    result.add(new HiveInputSplit(is, inputFormatClass.getName()));
  }
}
</code></pre></div>
<p>上面代码主要过程是：</p>

<blockquote>遍历每个输入目录，然后获得PartitionDesc对象，从该对象调用getInputFileFormatClass方法得到实际的InputFormat类，并调用其`getSplits(newjob, numSplits / dirs.length)`方法。
</blockquote>

<p>按照上面代码逻辑，似乎hive中每一个表都应该有一个InputFormat实现类。在hive中运行下面代码，可以查看建表语句：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hive&gt; show create table info; 
OK
CREATE  TABLE info(
  statist_date string, 
  statistics_date string, 
  inner_code string, 
  office_no string, 
  window_no string, 
  ticket_no string, 
  id_kind string, 
  id_no string, 
  id_name string, 
  area_center_code string)
ROW FORMAT DELIMITED 
  FIELDS TERMINATED BY &#39;\;&#39; 
  LINES TERMINATED BY &#39;\n&#39; 
STORED AS INPUTFORMAT 
  &#39;org.apache.hadoop.mapred.TextInputFormat&#39; 
OUTPUTFORMAT 
  &#39;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&#39;
LOCATION
  &#39;hdfs://node:8020/user/hive/warehouse/info&#39;
TBLPROPERTIES (
  &#39;numPartitions&#39;=&#39;0&#39;, 
  &#39;numFiles&#39;=&#39;1&#39;, 
  &#39;transient_lastDdlTime&#39;=&#39;1378245263&#39;, 
  &#39;numRows&#39;=&#39;0&#39;, 
  &#39;totalSize&#39;=&#39;301240320&#39;, 
  &#39;rawDataSize&#39;=&#39;0&#39;)
Time taken: 0.497 seconds
</code></pre></div>
<p>从上面可以看到info表的INPUTFORMAT为<code class="prettyprint">org.apache.hadoop.mapred.TextInputFormat</code>，TextInputFormat继承自FileInputFormat。FileInputFormat是一个抽象类，它最重要的功能是为各种InputFormat提供统一的getSplits()方法，该方法最核心的是文件切分算法和Host选择算法。</p>

<p>算法如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">long length = file.getLen();
long goalSize = totalSize / (numSplits == 0 ? 1 : numSplits);
long minSize = Math.max(job.getLong(org.apache.hadoop.mapreduce.lib.input.
FileInputFormat.SPLIT_MINSIZE, 1), minSplitSize);

long blockSize = file.getBlockSize();
long splitSize = computeSplitSize(goalSize, minSize, blockSize);
long bytesRemaining = length;
while (((double) bytesRemaining)/splitSize &gt; SPLIT_SLOP) {
String[] splitHosts = getSplitHosts(blkLocations, 
    length-bytesRemaining, splitSize, clusterMap);
    splits.add(makeSplit(path, length-bytesRemaining, splitSize, 
               splitHosts));
    bytesRemaining -= splitSize;
}
</code></pre></div>
<hr>

<p><code class="prettyprint">华丽的分割线</code>：以下摘抄自<a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a></p>

<p><strong>1）、文件切分算法</strong> </p>

<p>文件切分算法主要用于确定InputSplit的个数以及每个InputSplit对应的数据段，FileInputSplit以文件为单位切分生成InputSplit。有三个属性值来确定InputSplit的个数：</p>

<ul>
<li>goalSize：该值由totalSize/numSplits来确定InputSplit的长度，它是根据用户的期望的InputSplit个数计算出来的；numSplits为用户设定的Map Task的个数，默认为1。 </li>
<li>minSize：由配置参数mapred.min.split.size（或者 <code class="prettyprint">mapreduce.input.fileinputformat.split.minsize</code>）决定的InputFormat的最小长度，默认为1。 </li>
<li>blockSize：HDFS中的文件存储块block的大小，默认为64MB。</li>
<li>numSplits=<code class="prettyprint">mapred.map.tasks</code> 或者 <code class="prettyprint">mapreduce.job.maps</code> </li>
</ul>

<p>这三个参数决定一个InputFormat分片的最终的长度，计算方法如下： </p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">splitSize = max{minSize,min{goalSize,blockSize}} 
</code></pre></div>
<p>计算出了分片的长度后，也就确定了InputFormat的数目。 </p>

<p><strong>2）、host选择算法</strong></p>

<p>InputFormat的切分方案确定后，接下来就是要确定每一个InputSplit的元数据信息。InputSplit元数据通常包括四部分，<code class="prettyprint">&lt;file,start,length,hosts&gt;</code>其意义为： </p>

<ul>
<li>file标识InputSplit分片所在的文件； </li>
<li>InputSplit分片在文件中的的起始位置； </li>
<li>InputSplit分片的长度； </li>
<li>分片所在的host节点的列表。 </li>
</ul>

<blockquote>
InputSplit的host列表的算作策略直接影响到运行作业的本地性。<br/>

我们知道，由于大文件存储在HDFS上的block可能会遍布整个Hadoop集群，而一个InputSplit分片的划分算法可能会导致一个split分片对应多个不在同一个节点上的blocks，这就会使得在Map Task执行过程中会涉及到读其他节点上的属于该Task的block中的数据，从而不能实现数据本地性，而造成更多的网络传输开销。<br/>
 
一个InputSplit分片对应的blocks可能位于多个数据节点地上，但是基于任务调度的效率，通常情况下，不会把一个分片涉及的所有的节点信息都加到其host列表中，而是选择包含该分片的数据总量的最大的前几个节点，作为任务调度时判断是否具有本地性的主要凭证。<br/>
 
FileInputFormat使用了一个启发式的host选择算法：首先按照rack机架包含的数据量对rack排序，然后再在rack内部按照每个node节点包含的数据量对node排序，最后选取前N个(N为block的副本数)node的host作为InputSplit分片的host列表。当任务地调度Task作业时，只要将Task调度给host列表上的节点，就可以认为该Task满足了本地性。 <br/>

从上面的信息我们可以知道，当InputSplit分片的大小大于block的大小时，Map Task并不能完全满足数据的本地性，总有一本分的数据要通过网络从远程节点上读数据，故为了提高Map Task的数据本地性，减少网络传输的开销，应尽量是InputFormat的大小和HDFS的block块大小相同。
</blockquote>

<hr>

<h1 id="toc_3">CombineHiveInputFormat</h1>

<p><code class="prettyprint">getSplits(JobConf job, int numSplits)</code>代码运行过程如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">init(job);
CombineFileInputFormatShim combine = ShimLoader.getHadoopShims().getCombineFileInputFormat();
    ShimLoader.loadShims(HADOOP_SHIM_CLASSES, HadoopShims.class);
        Hadoop23Shims
            HadoopShimsSecure.getCombineFileInputFormat()
</code></pre></div>
<p>CombineFileInputFormatShim继承了<code class="prettyprint">org.apache.hadoop.mapred.lib.CombineFileInputFormat</code>,CombineFileInputFormatShim的getSplits方法代码如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">public InputSplitShim[] getSplits(JobConf job, int numSplits) throws IOException {
  long minSize = job.getLong(&quot;mapred.min.split.size&quot;, 0);

  // For backward compatibility, let the above parameter be used
  if (job.getLong(&quot;mapred.min.split.size.per.node&quot;, 0) == 0) {
    super.setMinSplitSizeNode(minSize);
  }

  if (job.getLong(&quot;mapred.min.split.size.per.rack&quot;, 0) == 0) {
    super.setMinSplitSizeRack(minSize);
  }

  if (job.getLong(&quot;mapred.max.split.size&quot;, 0) == 0) {
    super.setMaxSplitSize(minSize);
  }

  InputSplit[] splits = (InputSplit[]) super.getSplits(job, numSplits);

  InputSplitShim[] isplits = new InputSplitShim[splits.length];
  for (int pos = 0; pos &lt; splits.length; pos++) {
    isplits[pos] = new InputSplitShim((CombineFileSplit)splits[pos]);
  }

  return isplits;
}
</code></pre></div>
<p>从上面代码可以看出，如果为CombineHiveInputFormat，则以下四个参数起作用：</p>

<ul>
<li>mapred.min.split.size 或者 mapreduce.input.fileinputformat.split.minsize</li>
<li>mapred.max.split.size 或者 mapreduce.input.fileinputformat.split.maxsize</li>
<li>mapred.min.split.size.per.rack 或者 mapreduce.input.fileinputformat.split.minsize.per.rack</li>
<li>mapred.min.split.size.per.node 或者 mapreduce.input.fileinputformat.split.minsize.per.node</li>
</ul>

<p>CombineFileInputFormatShim的getSplits方法最终会调用父类的getSplits方法，拆分算法如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">long left = locations[i].getLength();
long myOffset = locations[i].getOffset();
long myLength = 0;
do {
    if (maxSize == 0) {
        myLength = left;
    } else {
    if (left &gt; maxSize &amp;&amp; left &lt; 2 * maxSize) {
      myLength = left / 2;
    } else {
      myLength = Math.min(maxSize, left);
    }
    }
    OneBlockInfo oneblock = new OneBlockInfo(path, myOffset,
      myLength, locations[i].getHosts(), locations[i]
          .getTopologyPaths());
    left -= myLength;
    myOffset += myLength;

    blocksList.add(oneblock);
} while (left &gt; 0);
</code></pre></div>
<h1 id="toc_4">hive中如何确定map数</h1>

<p>总上总结如下：</p>

<p>如果<code class="prettyprint">hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat</code>，则这时候的参数如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hive&gt; set mapred.min.split.size;
mapred.min.split.size=1
hive&gt; set mapred.map.tasks;
mapred.map.tasks=2
hive&gt; set dfs.blocksize;
dfs.blocksize=134217728
</code></pre></div>
<p>上面参数中mapred.map.tasks为2，dfs.blocksize（使用的是cdh-4.3.0版本的hadoop，这里block和size之间没有逗号）为128M。</p>

<p>假设有一个文件为200M，则按上面HiveInputFormat的split算法：</p>

<p>1、文件总大小为200M，goalSize=200M /2 =100M，minSize=1 ，splitSize = max{1,min{100M,128M}} =100M</p>

<p>2、200M / 100M &gt;1.1,故第一块大小为100M</p>

<p>3、剩下文件大小为100M，小于128M，故第二块大小为100M。</p>

<p>如果<code class="prettyprint">hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat</code>，则这时候的参数如下：</p>
<div class="highlight"><pre><code class="text language-text" data-lang="text">hive&gt; set mapred.min.split.size;
mapred.min.split.size=1
hive&gt; set mapred.max.split.size;
mapred.max.split.size=67108864
hive&gt; set mapred.min.split.size.per.rack;
mapred.min.split.size.per.rack=1
hive&gt; set mapred.min.split.size.per.node;
mapred.min.split.size.per.node=1
hive&gt; set dfs.blocksize;
dfs.blocksize=134217728
</code></pre></div>
<p>上面参数中mapred.max.split.size为64M，dfs.blocksize（使用的是cdh-4.3.0版本的hadoop，这里block和size之间没有逗号）为128M。</p>

<p>假设有一个文件为200M，则按上面CombineHiveInputFormat的split算法：</p>

<p>1、128M &lt; 200M &lt;128M X 2，故第一个block大小为128M</p>

<p>2、剩下文件大小为200M-128M=72M，72M &lt; 128M,故第二块大小为72M</p>

<h1 id="toc_5">总结</h1>

<p>网上有一些文章关于hive中如何控制map数的文章是否考虑的不够全面，没有具体情况具体分析。简而言之，当InputFormat的实现类为不同类时，拆分块算法都不一样，相关设置参数也不一样，需要具体分析。</p>

<h2 id="toc_6">1. map数不是越多越好</h2>

<p>如果一个任务有很多小文件（远远小于块大小128m）,则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。
而且，同时可执行的map数是受限的。</p>

<h2 id="toc_7">2. 如何适当的增加map数？</h2>

<ul>
<li>将数据导入到hive前，手动将大文件拆分为小文件</li>
<li>指定map数，使用insert或者create as select语句将一个表导入到另一个表，然后对另一张表做查询</li>
</ul>

<h2 id="toc_8">3. 一些经验</h2>

<ul>
<li><p>合并小文件可以减少map数，但是会增加网络IO。</p></li>
<li><p>尽量使拆分块大小和hdfs的块大小接近，避免一个拆分块大小上的多个hdfs块位于不同数据节点，从而降低网络IO。</p></li>
<li><p>根据实际情况，控制map数量需要遵循两个原则：<code class="prettyprint">使大数据量利用合适的map数</code>；<code class="prettyprint">使单个map任务处理合适的数据量。</code></p></li>
</ul>

<h1 id="toc_9">参考文章</h1>

<ul>
<li>[1] <a href="http://f.dataguru.cn/thread-149820-1-1.html">【hive】hive的查询注意事项以及优化总结</a></li>
<li>[2] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c010178qd.html">Hadoop中map数的计算</a></li>
<li>[3] <a href="http://blog.sina.com.cn/s/blog_6ff05a2c0101aqvv.html">[Hive]从一个经典案例看优化mapred.map.tasks的重要性</a></li>
<li>[4] <a href="http://superlxw1234.iteye.com/blog/1582880">hive优化之------控制hive任务中的map数和reduce数</a></li>
<li>[5] <a href="http://www.searchtb.com/2010/12/hadoop-job-tuning.html">Hadoop Job Tuning</a></li>
<li>[6] <a href="http://www.tuicool.com/articles/77f2Af">Hive配置项的含义详解（2）</a></li>
<li>[7] <a href="http://blog.csdn.net/lalaguozhe/article/details/9053645">Hive小文件合并调研</a>
<a href="http://flyingdutchman.iteye.com/blog/1876400">Hadoop深入学习：InputFormat组件</a></li>
</ul>

    </div>

    -EOF-
   <hr>

   <div class="row status">
	  <div class="col-md-6">
		<ul class="tag_box list-inline">
		
		    <li><i class="icon-folder-open"></i></li>
		    
		    


  
     
    	<li><a href="/categories.html#hadoop-ref">
    		hadoop
    	</a></li>
    
  



		

		
		    <li><i class="icon-tags"></i></li>
		    
		    


    
     
    	<li><a href="/tags.html#hive-ref">hive</a></li>
     
    	<li><a href="/tags.html#mapreduce-ref">mapreduce</a></li>
    
  






		
        </ul>
      </div>
      <div class="col-md-3">
        <div class="btn-group">
          
            <a class="btn btn-default btn-sm" href="/linux/2013/08/31/my-jekyll-config" title="我的jekyll配置和修改">&laquo; Prev</a>
          
            <a class="btn btn-default btn-sm" href="/archive.html">Archive</a>
          
            <a class="btn btn-default btn-sm" href="/work/2013/09/08/recent-work" title="最近的工作">Next &raquo;</a>
          
        </div>
      </div>
      <div class="col-md-3 visible-lg visible-md">
        <div id="bdshare" class="bdshare_t bds_tools_24 get-codes-bdshare btn-group pull-right">
          <a class="bds_tsina"></a>
          <a class="bds_tqq"></a>
          <a class="bds_t163"></a>
          <a class="bds_renren"></a>
          <span class="bds_more"></span>
        </div>
      </div>
    </div>
    <hr>
    


     <div id="comments">
  	<div class="ds-thread" data-title="hive中如何确定map数 - JavaChen Blog"></div>
   </div> 
     <script type="text/javascript">
      var duoshuoQuery = {short_name:"javachen"};
      (function() {
        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = 'http://static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
      })();
    </script>






  </div>
</div>


      <hr>
      <footer>
        <p>
          &copy; 2009-2014 <a href="/" target="_blank">JavaChen</a>
          <span class="pull-right text-muted">
            Powered by
            <a href="https://github.com/javachen/jekyll-bootstrap-3" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll-Bootstrap-3</a>
            and <a href="http://getbootstrap.com" target="_blank">Twitter Bootstrap 3.1.1</a> |<script language="javascript" type="text/javascript" src="http://js.users.51.la/12111481.js"></script>
<noscript><a href="http://www.51.la/?12111481" target="_blank"><img alt="Statistic" src="http://img.users.51.la/12111481.asp" style="border:none" /></a></noscript>

          </span>
        </p>
              <div id="toTop"><a href="#">▲</a><a href="#footer">▼</a></div>

      </footer>
    </div>

        <!-- Baidu Button BEGIN -->
    <script type="text/javascript" id="bdshell_js"></script>
    <script>document.write(unescape('%3Cscript%20type%3D%22text/javascript%22%20id%3D%22bdshare_js%22%20data%3D%22type%3Dtools%26amp%3Buid%3D1539895%22%3E%3C/script%3E'));</script>
    <script type="text/javascript">
      var bds_config = {
        'review':'normal',
        'snsKey':{
        }
      };
      document.getElementById("bdshell_js").src = "http://bdimg.share.baidu.com/static/js/shell_v2.js?cdnversion=" + Math.ceil(new Date()/3600000)
    </script>
    <!-- Baidu Button END -->

    <script type="text/javascript" src="//cdn.staticfile.org/jquery/1.8.3/jquery.min.js"></script>
    <script type="text/javascript" src="//cdn.staticfile.org/twitter-bootstrap/3.1.1/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
    <script type="text/javascript" src="/assets/themes/bootstrap/js/main.js"></script>
  </body>
</html>

